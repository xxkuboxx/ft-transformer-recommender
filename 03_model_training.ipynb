{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd98e32-da7e-4f15-9b40-263ba54284a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import rtdl\n",
    "from typing import List, Dict, Any\n",
    "from tqdm import tqdm\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "from sentence_transformers.readers import InputExample\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce11c2ca-4107-440f-9c08-e755cfcd58a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "Device Name: NVIDIA GeForce GTX 1050 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "# --- デバイスの設定 ---\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"GPU is not available. Training on CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c53230-91dc-440b-ae46-d0564602d2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 定数とデータの読み込み ---\n",
    "# 生のInputExample (辞書を含む) を読み込む\n",
    "TMP_DATA_DIR = 'tmp_data/'\n",
    "OUTPUT_PATH = 'tmp_data/03_ftt_instacart_recommender'\n",
    "train_examples_path = os.path.join(TMP_DATA_DIR, '02_train_examples.pkl')\n",
    "with open(train_examples_path, 'rb') as f:\n",
    "    train_examples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0f35851-af68-4f70-81e8-34930c48fdce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- モデルの定義とインスタンス化 ---\n",
    "class TabularFTTransformer(nn.Module):\n",
    "    def __init__(self, ft_transformer_model: nn.Module, numerical_feature_names: List[str], categorical_feature_names: List[str]):\n",
    "        super().__init__()\n",
    "        self.ft_transformer, self.numerical_feature_names, self.categorical_feature_names = ft_transformer_model, numerical_feature_names, categorical_feature_names\n",
    "    def tokenize(self, item_feature_dicts: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        x_num = torch.tensor([[item.get(feat, 0.0) for feat in self.numerical_feature_names] for item in item_feature_dicts], dtype=torch.float32)\n",
    "        x_cat = torch.tensor([[int(item.get(feat, 0)) for feat in self.categorical_feature_names] for item in item_feature_dicts], dtype=torch.long)\n",
    "        return {'x_num': x_num, 'x_cat': x_cat}\n",
    "    def forward(self, features: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        embeddings = self.ft_transformer(features['x_num'], features['x_cat'])\n",
    "        return {'sentence_embedding': embeddings}\n",
    "    def get_sentence_embedding_dimension(self) -> int:\n",
    "        return self.ft_transformer.d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e46859-9bd8-460a-9c4b-2ec08846c8df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): TabularFTTransformer(\n",
       "    (ft_transformer): FTTransformer(\n",
       "      (feature_tokenizer): FeatureTokenizer(\n",
       "        (num_tokenizer): NumericalFeatureTokenizer()\n",
       "        (cat_tokenizer): CategoricalFeatureTokenizer(\n",
       "          (embeddings): Embedding(157, 192)\n",
       "        )\n",
       "      )\n",
       "      (cls_token): CLSToken()\n",
       "      (transformer): Transformer(\n",
       "        (blocks): ModuleList(\n",
       "          (0): ModuleDict(\n",
       "            (attention): MultiheadAttention(\n",
       "              (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (ffn): FFN(\n",
       "              (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "              (activation): ReGLU()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "            )\n",
       "            (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (output): Identity()\n",
       "            (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1-2): 2 x ModuleDict(\n",
       "            (attention): MultiheadAttention(\n",
       "              (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.2, inplace=False)\n",
       "            )\n",
       "            (ffn): FFN(\n",
       "              (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "              (activation): ReGLU()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "            )\n",
       "            (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (output): Identity()\n",
       "            (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (head): Head(\n",
       "          (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): ReLU()\n",
       "          (linear): Linear(in_features=192, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (モデルのインスタンス化とGPUへの移動)\n",
    "item_profiles_df = pd.read_csv(os.path.join(TMP_DATA_DIR, '02_item_profiles_scaled.csv'))\n",
    "numerical_feature_names = ['reorder_rate', 'avg_add_to_cart_order', 'total_orders', 'unique_users', 'avg_days_since_prior_order']\n",
    "categorical_feature_names = ['aisle_id', 'department_id']\n",
    "cat_cardinalities = [int(item_profiles_df[col].max()) + 1 for col in categorical_feature_names]\n",
    "D_OUT = 64\n",
    "core_ft_transformer = rtdl.FTTransformer.make_default(n_num_features=len(numerical_feature_names), cat_cardinalities=cat_cardinalities, last_layer_query_idx=[-1], d_out=D_OUT)\n",
    "ftt_wrapper = TabularFTTransformer(ft_transformer_model=core_ft_transformer, numerical_feature_names=numerical_feature_names, categorical_feature_names=categorical_feature_names)\n",
    "model = SentenceTransformer(modules=[ftt_wrapper])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a6cffdb-550a-4c37-ad57-95087d217311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- データローダーと損失関数の設定 ---\n",
    "def smart_collate_fn(batch):\n",
    "    anchor_dicts = [example.texts[0] for example in batch]\n",
    "    positive_dicts = [example.texts[1] for example in batch]\n",
    "    # ★ テンソル化はcollate_fnの中で、CPU上で行う\n",
    "    anchor_features = model[0].tokenize(anchor_dicts)\n",
    "    positive_features = model[0].tokenize(positive_dicts)\n",
    "    features = [anchor_features, positive_features]\n",
    "    labels = torch.zeros(len(batch))\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c1899d-89d1-46b5-9143-a90bd1c78a33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultipleNegativesRankingLoss(\n",
       "  (model): SentenceTransformer(\n",
       "    (0): TabularFTTransformer(\n",
       "      (ft_transformer): FTTransformer(\n",
       "        (feature_tokenizer): FeatureTokenizer(\n",
       "          (num_tokenizer): NumericalFeatureTokenizer()\n",
       "          (cat_tokenizer): CategoricalFeatureTokenizer(\n",
       "            (embeddings): Embedding(157, 192)\n",
       "          )\n",
       "        )\n",
       "        (cls_token): CLSToken()\n",
       "        (transformer): Transformer(\n",
       "          (blocks): ModuleList(\n",
       "            (0): ModuleDict(\n",
       "              (attention): MultiheadAttention(\n",
       "                (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "              (ffn): FFN(\n",
       "                (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "                (activation): ReGLU()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "              )\n",
       "              (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output): Identity()\n",
       "              (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1-2): 2 x ModuleDict(\n",
       "              (attention): MultiheadAttention(\n",
       "                (W_q): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (W_k): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (W_v): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (W_out): Linear(in_features=192, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.2, inplace=False)\n",
       "              )\n",
       "              (ffn): FFN(\n",
       "                (linear_first): Linear(in_features=192, out_features=512, bias=True)\n",
       "                (activation): ReGLU()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (linear_second): Linear(in_features=256, out_features=192, bias=True)\n",
       "              )\n",
       "              (attention_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (ffn_residual_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (output): Identity()\n",
       "              (attention_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (ffn_normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (head): Head(\n",
       "            (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): ReLU()\n",
       "            (linear): Linear(in_features=192, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cross_entropy_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=1024,\n",
    "    collate_fn=smart_collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "train_loss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "870da6eb-c7a6-4a92-8b00-e77a48ad4f72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 4883/4883 [14:48<00:00,  5.50it/s, loss=6.52]\n"
     ]
    }
   ],
   "source": [
    "# モデル学習\n",
    "epochs = 1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_scheduler(\n",
    "    name=\"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=int(total_steps * 0.1),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        features, labels = batch\n",
    "        # ★ バッチごとに、CPUテンソルをGPUに転送\n",
    "        features_on_device = [{key: val.to(device) for key, val in feature.items()} for feature in features]\n",
    "        labels_on_device = labels.to(device)\n",
    "\n",
    "        loss_value = train_loss(features_on_device, labels_on_device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss_value.item()})\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(OUTPUT_PATH, \"pytorch_model.bin\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
